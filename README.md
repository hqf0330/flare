# Flare: è½»é‡çº§ Flink Java å¼€å‘æ¡†æ¶

Flare æ˜¯ä¸€ä¸ªä¸“ä¸º **Flink 1.19+** å’Œ **JDK 17** æ·±åº¦å®šåˆ¶çš„é«˜çº§å¼€å‘æ¡†æ¶ã€‚å®ƒé€šè¿‡â€œæ³¨è§£é©±åŠ¨é…ç½®â€å’Œâ€œæ ‡å‡†åŒ–ç”Ÿå‘½å‘¨æœŸç®¡ç†â€ï¼Œæå¤§åœ°ç®€åŒ–äº† Flink JAR ä»»åŠ¡çš„å¼€å‘æˆæœ¬ï¼Œå¹¶å†…ç½®äº†ä¼ä¸šçº§çš„ç›‘æ§ã€æ²»ç†ä¸å®¹ç¾èƒ½åŠ›ã€‚

## ğŸš€ æ ¸å¿ƒç‰¹æ€§

*   **æ³¨è§£é©±åŠ¨é…ç½®**ï¼šé€šè¿‡ `@Streaming`, `@Kafka`, `@Jdbc`, `@State` ç­‰æ³¨è§£æ›¿ä»£ç¹ççš„ä»£ç é…ç½®ï¼Œå®ç°é›¶æ ·æ¿ä»£ç ã€‚
*   **æ ‡å‡†åŒ–ç”Ÿå‘½å‘¨æœŸ**ï¼šå®šä¹‰äº†æ¸…æ™°çš„ `init` -> `before` -> `process` -> `after` ä»»åŠ¡æµï¼Œæ”¯æŒ `Step1-6` åˆ†é˜¶æ®µé€»è¾‘æ‹†åˆ†ã€‚
*   **ç°ä»£ Java é€‚é…**ï¼šæ·±åº¦æ”¯æŒ **Java 17 record**ï¼Œå®ç° Kafka JSON æ•°æ®åˆ° DTO çš„è‡ªåŠ¨ååºåˆ—åŒ–ã€‚
*   **å·¥ä¸šçº§å®¹ç¾**ï¼šä¸€é”®å¼€å¯ **RocksDB** çŠ¶æ€åç«¯ã€å¢é‡æ£€æŸ¥ç‚¹ï¼ˆIncremental Checkpointï¼‰ä»¥åŠå…¨å±€çŠ¶æ€è¿‡æœŸï¼ˆTTLï¼‰ç®¡ç†ã€‚
*   **å…¨æ–¹ä½å¯è§‚æµ‹æ€§**ï¼š
    *   **åˆ†å¸ƒå¼æŒ‡æ ‡**ï¼šä¸€è¡Œä»£ç å®ç°è·¨èŠ‚ç‚¹çš„åˆ†å¸ƒå¼ç´¯åŠ å™¨ä¸å®æ—¶ Metrics æ‰“ç‚¹ã€‚
    *   **è‡ªåŠ¨è¡€ç¼˜**ï¼šå¯åŠ¨å³æ‰“å°æ•°æ®æºï¼ˆSourceï¼‰ä¸è½åœ°ç«¯ï¼ˆSinkï¼‰çš„æ‹“æ‰‘å…³ç³»ã€‚
    *   **æ—¥å¿—è¿½è¸ª**ï¼šè‡ªåŠ¨æ³¨å…¥ `MDC` å˜é‡ï¼ˆappNameï¼‰ï¼Œæ”¯æŒåœ¨æµ·é‡é›†ç¾¤æ—¥å¿—ä¸­ç§’çº§æ£€ç´¢ã€‚
*   **ç”Ÿäº§å¢å¼º**ï¼šå†…ç½® JDBC **Upsert (å¹‚ç­‰å†™å…¥)** è‡ªåŠ¨ç”Ÿæˆé€»è¾‘ï¼Œè§£å†³ä»»åŠ¡é‡å¯å¯¼è‡´çš„æ•°æ®é‡å¤ç—›ç‚¹ã€‚

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

*   **Runtime**: JRE 17+
*   **Engine**: Apache Flink 1.19.1
*   **Build**: Maven 3.8+
*   **Frameworks**: Lombok, Jackson, SLF4J

## ğŸ“¦ å¿«é€Ÿå¼€å§‹

### 1. å¼•å…¥ä¾èµ–
åœ¨ä½ çš„ `pom.xml` ä¸­å¼•å…¥ `flare-flink` æ¨¡å—ã€‚

### 2. å¼€å‘ç¬¬ä¸€ä¸ª Flare ä»»åŠ¡
ç»§æ‰¿ `FlinkStreaming` åŸºç±»ï¼Œä½¿ç”¨æ³¨è§£å®šä¹‰ç¯å¢ƒï¼Œå¹¶åœ¨ `process` ä¸­ç¼–å†™ä¸šåŠ¡é€»è¾‘ã€‚

```java
@Streaming(parallelism = 2, interval = 10)
@Kafka(
    brokers = "localhost:9092", 
    topics = "user_action", 
    groupId = "flare_group",
    watermarkStrategy = "bounded"
)
@Jdbc(
    url = "jdbc:mysql://localhost:3306/db",
    sql = "INSERT INTO t_report(id, val) VALUES (?, ?)",
    upsertMode = "mysql",
    keyColumns = "id"
)
public class MyFirstTask extends FlinkStreaming {

    // å®šä¹‰æ•°æ®æ¨¡å‹
    public record UserAction(Long id, String action) {}

    @Override
    public void process() {
        // 1. è‡ªåŠ¨è§£æ Kafka JSON ä¸º Record
        DataStream<UserAction> stream = this.kafkaSourceFromConf(UserAction.class);
        
        // 2. ç®—å­ UID ç®¡ç† (ç¡®ä¿çŠ¶æ€æ¢å¤å…¼å®¹æ€§)
        this.uname(stream, "source_id");

        // 3. åˆ†å¸ƒå¼æŒ‡æ ‡æ‰“ç‚¹
        stream.map(new FlareRichMapFunction<UserAction, UserAction>() {
            @Override
            public UserAction map(UserAction value) {
                counter("user_login_count");
                return value;
            }
        });

        // 4. è‡ªåŠ¨æ”’æ‰¹ã€è‡ªåŠ¨ç”Ÿæˆ Upsert SQL å†™å…¥ MySQL
        this.jdbcSinkFromConf(stream, (ps, value) -> {
            ps.setLong(1, value.id());
            ps.setString(2, value.action());
        });
    }

    public static void main(String[] args) {
        FlinkJobLauncher.run(MyFirstTask.class, args);
    }
}
```

## ğŸ“– æ³¨è§£è¯¦è§£

### `@Streaming`
æ§åˆ¶ Flink è¿è¡Œæ¨¡å¼ã€å¹¶è¡Œåº¦ã€Checkpoint é—´éš”ç­‰ã€‚

### `@Kafka`
é…ç½® Kafka è¿æ¥ä¿¡æ¯ã€‚æ”¯æŒ `startFromTimestamp`ï¼ˆæ—¶é—´æˆ³å¯åŠ¨ï¼‰å’Œ `config`ï¼ˆåº•å±‚å‚æ•°é€ä¼ ï¼‰ã€‚

### `@Jdbc`
é…ç½®æ•°æ®åº“è¿æ¥ã€‚æ ¸å¿ƒå±æ€§ `upsertMode="mysql"` ä¼šè‡ªåŠ¨å°† `INSERT` è¯­å¥å¢å¼ºä¸º `ON DUPLICATE KEY UPDATE`ã€‚

### `@State`
é…ç½®çŠ¶æ€åç«¯ã€‚æ”¯æŒ `backend="rocksdb"`ï¼Œå¹¶å¯æŒ‡å®š `checkpointDir` çš„ HDFS è·¯å¾„ã€‚

## ğŸ›¡ï¸ ç”Ÿäº§ç¯å¢ƒå»ºè®®

1.  **çŠ¶æ€æ¢å¤**ï¼šåŠ¡å¿…ä½¿ç”¨ `this.uname(stream, "unique_id")` ä¸ºå…³é”®ç®—å­è®¾ç½® IDã€‚
2.  **æ—¥å¿—æ£€ç´¢**ï¼šåœ¨æ—¥å¿—é…ç½®æ–‡ä»¶ï¼ˆlogback.xmlï¼‰çš„ Pattern ä¸­åŠ å…¥ `%X{appName}`ã€‚
3.  **èµ„æºå›æ”¶**ï¼šæ¡†æ¶å†…ç½®äº† JVM Shutdown Hookï¼Œç¡®ä¿åœ¨ä»»åŠ¡åœæ­¢æ—¶ä¼˜é›…å…³é—­æ•°æ®åº“è¿æ¥ã€‚

## ğŸ“ å¼€æºåè®®
Apache License 2.0
